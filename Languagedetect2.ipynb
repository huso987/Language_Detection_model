{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d8c5c6-7a2a-4659-820a-06c0365a3473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 19:07:22.770971: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-26 19:07:22.771238: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-26 19:07:22.898242: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-26 19:07:23.174236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-26 19:07:26.917393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classification_rep' from 'sklearn.metrics' (/home/huseyin/.local/lib/python3.10/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalAccuracy\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_rep\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'classification_rep' from 'sklearn.metrics' (/home/huseyin/.local/lib/python3.10/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "# kütüphaneler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b2d23-098c-43e2-8dc7-43b80c0ca2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT modelini yükleme\n",
    "model_name = 'dbmdz/bert-base-turkish-128k-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3872c2-38a8-4b9b-9725-5f855dcca163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini yükleme (örnek olarak bir dil veri seti kullanıldı)\n",
    "data = pd.read_csv('/content/drive/MyDrive/Colab çalışma/Language_Detection.csv')\n",
    "#Tekrarlı veri kontrolu\n",
    "data.duplicated().sum()\n",
    "#Tekrarlı veriyi silme\n",
    "data.drop_duplicates(inplace= True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374aa083-9b30-4ee1-8d8b-271f30d4bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini train ve test setlerine ayırma\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# LabelEncoder oluşturma\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Eğitim verileri için Language sütununu dönüştürme\n",
    "train_labels_encoded = label_encoder.fit_transform(train_data['Language'])\n",
    "\n",
    "# Test verileri için Language sütununu dönüştürme\n",
    "test_labels_encoded = label_encoder.transform(test_data['Language'])\n",
    "\n",
    "# Eğitim etiketlerini one-hot encoding yapma\n",
    "train_labels = to_categorical(train_labels_encoded, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Test etiketlerini one-hot encoding yapma\n",
    "test_labels = to_categorical(test_labels_encoded, num_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1ffe1-1b77-4794-b625-29a0149af813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini BERT için uygun formata dönüştürme\n",
    "def convert_to_input(data):\n",
    "    encodings = tokenizer(\n",
    "        data['Text'].tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return encodings\n",
    "\n",
    "train_encodings = convert_to_input(train_data)\n",
    "test_encodings = convert_to_input(test_data)\n",
    "\n",
    "# BERT modelini ince ayarlama için özelleştirme\n",
    "input_layer = Input(shape=(128,), dtype='int32')\n",
    "bert_output = bert_model(input_layer)\n",
    "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(bert_output.logits)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbdada-bc66-47b8-aea0-d379d476de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli derleme\n",
    "optimizer = Adam(learning_rate=0.0001)  # Öğrenme oranını düşürme\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71476c2a-eef3-4647-94c7-65fb5380d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli eğitme\n",
    "history = model.fit(\n",
    "    x=train_encodings['input_ids'],\n",
    "    y=train_labels,\n",
    "    validation_data=(test_encodings['input_ids'], test_labels),\n",
    "    epochs=5,  # Daha fazla epoch eğitmeyi deneyebilirsiniz\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3cd81-ad74-47ee-98f8-2cff0b169c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli kaydetme\n",
    "model.save('/content/drive/MyDrive/Colab çalışma/language_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fd7d2-c1bd-481b-b605-24acdcb7daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim sürecinin doğruluk (accuracy) ve kayıp (loss) grafiği\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0491e7-5d44-4b23-83c7-4b050e0c2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahminler yapma\n",
    "predictions = model.predict(test_encodings['input_ids'])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94945827-c16c-44b5-b966-32b99098ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80755d9b-0310-40ae-b352-ebf0d03dad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "class_report = classification_report(true_classes, predicted_classes)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
